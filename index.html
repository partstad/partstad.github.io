<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PartSTAD: 2D-to-3D Part Segmentation Task Adaptation">
  <meta name="keywords" content="PartSTAD, Part Segmentation, Few-shot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PartSTAD: 2D-to-3D Part Segmentation Task Adaptation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://partstad.github.io">
            PartSTAD
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PartSTAD: 2D-to-3D Part Segmentation Task Adaptation</h1>
          <div style="font-size:x-large;">ECCV 2024</div><br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kormachine.github.io">Hyunjin Kim</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://mhsung.github.io">Minhyuk Sung</a><sup>2</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>KRAFTON Inc,</span>
            <span class="author-block"><sup>2</sup>KAIST</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2401.05906"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/KAIST-Visual-AI-Group/PartSTAD/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered is-flex-direction-column">
      <div class="container" style="width:90%;">
        <img src="./figure/teaser.png" alt="header" style="max-width:80%;">
      </div>
  </div>
</section><br><br><hr>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce <span class="dnerf">PartSTAD</span>, a method designed for the task adaptation of 2D-to-3D segmentation lifting. Recent studies have highlighted the advantages of utilizing 2D segmentation models to achieve high-quality 3D segmentation through few-shot adaptation. However, previous approaches have focused on adapting 2D segmentation models for domain shift to rendered images and synthetic text descriptions, rather than optimizing the model specifically for 3D segmentation. Our proposed task adaptation method finetunes a 2D bounding box prediction model with an objective function for 3D segmentation. We introduce weights for 2D bounding boxes for adaptive merging and learn the weights using a small additional neural network. Additionally, we incorporate SAM, a foreground segmentation model on a bounding box, to improve the boundaries of 2D segments and consequently those of 3D segmentation. Our experiments on the PartNet-Mobility dataset show significant improvements with our task adaptation approach, achieving a <b>7.0%p</b> increase in mIoU and a <b>5.2%p</b> improvement in mAP<sub>50</sub> for semantic and instance segmentation compared to the SotA few-shot 3D segmentation model.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section><br><br><hr>


<section class="section">
  <div class="container is-max-desktop">
    <!-- <div class="column is-four-fifths"></div> -->
      <!-- Abstract. -->
    <div class="columns is-centered has-text-centered is-flex-direction-column">
      <h2 class="title is-4">Overall Pipeline</h2>
      <div class="container">
        <img src="./figure/main_pipeline.png" alt="Framework" style="max-width:90%;">
      </div>
      <div class="content has-text-justified">
        <p></p>
        <p style="font-size: 110%;">
          Our approach begins by rendering the provided 3D point cloud from multiple viewpoints. Subsequently, we extract 2D bounding boxes for its parts using GLIP (Bounding Box Prediction); note that we utilize the finetuned GLIP model from PartSLIP . Following this, we convert the bounding boxes into segmentation masks using SAM, extracting the foreground region for each bounding box (SAM Mask Integration). Next, we predict weights for all the masks and adaptively combine them into a 3D representation (2D-to-3D task adaptation). The final step involves obtaining the segmentation label for the input point cloud. The GLIP and SAM models are frozen, while only our novel weight prediction network is trained per category in a few-shot setting (8 objects).
        </p>
      </div>
    </div>
  </div>
</section><br><br><hr>

<section class="section"></section>
  <div class="container is-max-desktop">
    <!-- <div class="column is-four-fifths"></div> -->
      <!-- Abstract. -->
    <div class="columns is-centered has-text-centered is-flex-direction-column">
      <h2 class="title is-4">Key Idea: Task Adaptation instead of Domain Adaptation</h2>
      <div class="container">
        <img src="./figure/motivation.png" alt="KeyIdea" style="max-width:90%;">
      </div>
      <div class="content has-text-justified">
        <p></p>
        <p style="font-size: 110%;">
          Although the main task is 3D part segmentation, Previous work  finetunes 2D VLM (GLIP) using VLM’s objective instead of main task as an objective. Thus we propose a <b>task adaptation approach that adapts 2D task to 3D task</b>, instead of the conventional domain adaptation, which fails to fully exploiting 3D segmentation results.
        </p>
        <p style="font-size: 110%;">
          However, our new objective function (3D mRIoU Loss) is not differentiable w.r.t GLIP’s output, we propose an alternative approach, <b>Weight Prediction & Score Reformulation</b>. (Please refer to the main paper for details.)
        </p>
        <p style="font-size: 110%;">
          Additionally, we improve performance by using the bounding boxes predicted by GLIP as conditions for SAM to perform mask refinement.
        </p>
      </div>
    </div>
  </div>
</section><br><br><hr>


<section class="hero teaser">
  <div class="columns is-centered has-text-centered is-flex-direction-column"><br>
    <h2 class="title is-4">Qualitative Results on PartNet-Mobility Dataset</h2>
  </div>
  <div class="container is-max-desktop is-centered has-text-centered">
    <p style="font-size: 120%;"><span class="dnerf">PartSTAD</span> segments 3D parts more precisely with clearer boundaries, even for small (Chair) and thin (Clock) parts.
    </p>
  </div>
  <br><br>
  <div class="columns is-centered has-text-centered is-flex-direction-column">
    <div class="container" style="width:75%;">
      <img src="./figure/partnet_mobility_qualitative.png" alt="comparison-02" style="max-width:80%;">
    </div>
  </div>
</section><br><br><hr>

  </div>
</section>

<section class="hero teaser"></section>
  <div class="columns is-centered has-text-centered is-flex-direction-column"><br>
    <h2 class="title is-4">Qualitative Results on OmniObject3D Dataset</h2>
  </div>
  <div class="container is-max-desktop is-centered has-text-centered">
    <p style="font-size: 120%;">Although <span class="dnerf">PartSTAD</span> is trained on a synthetic dataset, it also performs well on the real scanned 3D object dataset, OmniObject3D.
    </p>
  </div>
  <br><br>
  <div class="columns is-centered has-text-centered is-flex-direction-column">
    <div class="container" style="width:75%;">
      <img src="./figure/omniobject3d_qualitative.png" alt="comparison-02" style="max-width:80%;">
    </div>
  </div>
</section><br><br><hr>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceeding{kim2024partstad,
  author    = {Kim, Hyunjin and Sung, Minhyuk},
  title     = {PartSTAD: 2D-to-3D Part Segmentation Task Adaptation},
  booktitle   = {ECCV},
  year      = {2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The website is based on <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We thank 
            <a href="https://keunhong.com/">Keunhong Park</a> for kindly open-sourcing the source code.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
